{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knitr::opts_chunk$set(echo = TRUE, \n",
                "                      cache = TRUE, \n",
                "                      message = FALSE, \n",
                "                      warning = FALSE, \n",
                "                      dpi = 600)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introducción\n",
                "\n",
                "En este ejemplo, mostramos la capacidad de los algoritmos de Deep Learning para clasificar imágenes de radiodiagnóstico médico. El objetivo de este proyecto es entrenar a un algoritmo para que sea capaz de clasificar automáticamente una imágen de una radiografía de pecho en dos categorías (enferma vs no-enferma).\n",
                "\n",
                "# Proyectos previos\n",
                "\n",
                "Este proyecto es una adaptación del proyecto original de Michael Blum [tweeted](https://twitter.com/mblum_g/status/1475940763716444161?s=20) sobre el desafío [STOIC2021 - dissease-19 AI challenge](https://stoic2021.grand-challenge.org/stoic2021/). El proyecto roiginal de Michael partía de un conjunto de imágenes de pacientes con patología dissease-19 junto con otros pacientes sanos para hacer de contraste. Del proyecto original de Michael, [Olivier Gimenez](https://oliviergimenez.github.io/) utilizó un conjunto de datos similar al del proyetco original publicado en una competición de [Kaggle](https://en.wikipedia.org/wiki/Kaggle) repository <https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset>. La razón de utilizar este nuevo dataset es que era considerablemente más manejable que el original (280GB). El nuevo dataset pesaba alrededor de 250MB y contenía algo más de 1000 imágenes de pacientes sanos y enfermos. El código del proyecto de Olivier puede encontrase en [Github](https://github.com/oliviergimenez/bin-image-classif).\n",
                "\n",
                "# Conjunto de Datos\n",
                "\n",
                "En nuestro caso, inspirándonos en estos dos fantásticos proyectos previos, damos un paso más. En este proyecto, partimos de un conjunto de datos (imágenes médicas) de radio-diagnóstico que están disponibles en el repositorio abierto del [NIH](https://clinicalcenter.nih.gov/). El Centro Clínico NIH es un hospital dedicado únicamente a la investigación clínica en el campus de los Institutos Nacionales de Salud en Bethesda, Maryland (EEUU). En el post [10 repositorios de datos públicos relacionados con la salud y el bienestar](https://datos.gob.es/es/noticia/10-repositorios-de-datos-publicos-relacionados-con-la-salud-y-el-bienestar) se cita al NIH como uno de los orígenes de datos sanitarios de calidad.\n",
                "\n",
                "En particular, nuestro conjunto de datos está disponible públicamente [aquí](https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345). El repositorio incluye toda la información necesario para usarlo y en la descripción los autores comentan:\n",
                "\n",
                "> El examen de rayos X de tórax es uno de los exámenes de imágenes médicas más frecuentes y rentables. Sin embargo, el diagnóstico clínico de la radiografía de tórax puede ser un desafío y, a veces, se cree que es más difícil que el diagnóstico mediante imágenes de [TC](https://es.wikipedia.org/wiki/Tomograf%C3%ADa_axial_computarizada) (Tomografía Computerizada) de tórax\\_\n",
                "\n",
                "El conjunto de datos de rayos X de tórax comprende **112.120** imágenes de rayos X de vista frontal de **30.805** pacientes únicos con las **etiquetas de imágenes de catorce enfermedades** extraídas de texto (donde cada imagen puede tener múltiples etiquetas), extraídas de los informes radiológicos asociados utilizando procesamiento de lenguaje natural.\n",
                "\n",
                "Ejemplo de imágen del repositorio: ![imagen de paciente sano](../images/00012908_000.jpg)\n",
                "\n",
                "# El código paso a paso\n",
                "\n",
                "##Instalación de dependencias\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "install <- F\n",
                "if (install==T){\n",
                "install.packages(\"keras\")\n",
                "install.packages(\"httr\")\n",
                "install.packages(\"tidyverse\")\n",
                "install.packages(\"rmarkdown\")\n",
                "install.packages(\"reshape2\")\n",
                "install.packages(\"patchwork\")\n",
                "\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Carga de dependencias\n",
                "\n",
                "Lo primero que debemos hacer es cargar las dependencias (librerías) que vamos a necesitar en nuestro análisis. El paquete de R más representativo de este conjunto de dependencias es [Keras](https://keras.io/). En este [post]() ya comentamos sobre el uso de Keras como framework de Deep Learning.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(tidyverse)\n",
                "library(httr)\n",
                "library(rmarkdown)\n",
                "library(keras)\n",
                "library(reshape2)\n",
                "library(patchwork)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Acceso a datos\n",
                "\n",
                "_Esta sección solo es importante para aquellos usuarios que deseen ejecutar el código en Google Colab_\n",
                "\n",
                "Para ejecutar este Notebook en (Google Colab)[https://colab.research.google.com/]\n",
                "debemos de importar los datos al espacio local de trabajo de Colab. Los pasos son los siguientes:\n",
                "\n",
                "1. Accedemos a la [siguiente dirección](https://drive.google.com/drive/folders/1jZkgiSgT7ab_wQynxtkY4QpIxljbsWvi?usp=sharing) en Google Drive y descargamos el directorio comprimido de los datos.\n",
                "\n",
                "2. Descomprimimos el directorio en nuestro ordenador local.\n",
                "\n",
                "3. Creamos unos directorios en Google Colab para guardar los datos de las imágenes.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Creamos directorios locales\n",
                "system(\"mkdir data\")\n",
                "system(\"mkdir data/Pneumothorax\")\n",
                "system(\"mkdir data/No-Finding\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "4. Subimos manualmente los ficheros de imágen de acuerdo a la organización de cada carperta a Google Colab. Para ello, hacemos clic con botón derecho sobre cada una de los nuevos directorios en Colab y subimos las imágenes correspondientes.\n",
                "\n",
                "Una vez subidos los ficheros debemos de ver algo tal que así en Google Colab.\n",
                "\n",
                "Ejemplo de imágenes de datos: ![imágenes en Colab](../images/resultado_colab.jpeg)\n",
                "\n",
                "__NOTA IMPORTANTE__ \n",
                "\n",
                "LAS IMÁGENES DE ENTRENAMIENTO Y TEST OCUPAN UN VOLUMEN EN DISCO DE 25GB DEBIDO A SU ELEVADO NUMERO. EL USUARIO HA DE TENER EN CUENTA LOS TIEMPOS DE CARGA Y DESCARGA ASÍ COMO QUE ES POSIBLE QUE NO PUEDA CARGARLAS TODAS EN COLAB. CUANTAS MENOS IMAGENES SE CARGUEN EN COLAB PEORES SERAN LOS RESULTADOS DE LOS ENTRENAMIENTOS Y LAS PREDICCIONES.\n",
                "\n",
                "\n",
                "# Lectura de datos\n",
                "\n",
                "Utilizando esta función leemos y preprocesamos todas las imágenes con las que vamos a querer trabajar. Esta función procede del [post original](https://rpubs.com/spalladino14/653239) escrita por [Spencer Palladino](https://www.linkedin.com/in/spencer-palladino/).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "process_pix <- function(lsf) {\n",
                "  img <- lapply(lsf, image_load, color_mode = \"grayscale\") # grayscale the image\n",
                "  arr <- lapply(img, image_to_array) # turns it into an array\n",
                "  arr_resized <- lapply(arr, image_array_resize, \n",
                "                        height = 100, \n",
                "                        width = 100) # resize\n",
                "  arr_normalized <- normalize(arr_resized, axis = 1) #normalize to make small numbers \n",
                "  return(arr_normalized)\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "En este fragmento de código cargamos las imágenes desde de los directorios donde las hemos dejado previamente.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "lsf <- list.files(\"../data/Pneumothorax\", full.names = TRUE) \n",
                "\n",
                "# Restrinjo la lista a 1000 elementos. \n",
                "#lsf2 <- lsf[1:length(lsf)]\n",
                "lsf2 <- lsf[1:1500]\n",
                "\n",
                "dissease <- process_pix(lsf2)\n",
                "\n",
                "dissease <- dissease[,,,1]\n",
                "dissease_reshaped <- array_reshape(dissease, c(nrow(dissease), 100*100))\n",
                "\n",
                "# Imágenes de personas SIN patologías\n",
                "lsf3 <- list.files(\"../data/No-Finding\", full.names = TRUE) \n",
                "\n",
                "# Restrinjo la lista a 1000 elementos. \n",
                "#lsf4 <- lsf3[1:length(lsf3)]\n",
                "lsf4 <- lsf3[1:1500]\n",
                "\n",
                "ndissease <- process_pix(lsf4)\n",
                "ndissease  <- ndissease[,,,1]\n",
                "ndissease_reshaped <- array_reshape(ndissease, c(nrow(ndissease), 100*100))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tenemos `r nrow(dissease_reshaped)` imágenes de rayos-x de personas con enfermedad y `r nrow(dissease_reshaped)` imágenes de personas sin enfermedad.\n",
                "\n",
                "# Visualización previa de los datos/imágenes\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "scandissease <- reshape2::melt(dissease[10,,])\n",
                "plotdissease <- scandissease %>%\n",
                "  ggplot() +\n",
                "  aes(x = Var1, y = Var2, fill = value) + \n",
                "  geom_raster() +\n",
                "  labs(x = NULL, y = NULL, title = \"Raxos-x de personas con enfermedad\") + \n",
                "  scale_fill_viridis_c() + \n",
                "  theme(legend.position = \"none\")\n",
                "\n",
                "scanndissease <- reshape2::melt(ndissease[10,,])\n",
                "plotndissease <- scanndissease %>%\n",
                "  ggplot() +\n",
                "  aes(x = Var1, y = Var2, fill = value) + \n",
                "  geom_raster() +\n",
                "  labs(x = NULL, y = NULL, title = \"Raxos-x de personas sin enfermedad\") + \n",
                "  scale_fill_viridis_c() + \n",
                "  theme(legend.position = \"none\")\n",
                "\n",
                "library(patchwork)\n",
                "plotdissease + plotndissease\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Comenzamos el análisis\n",
                "\n",
                "Lo primero que vamos a hacer es mezclar las imágenes de pacientes con enfermedad y sin ella.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df <- rbind(cbind(dissease_reshaped, 1), # 1 = dissease\n",
                "            cbind(ndissease_reshaped, 0)) # 0 = no dissease\n",
                "set.seed(1234)\n",
                "shuffle <- sample(nrow(df), replace = F)\n",
                "df <- df[shuffle, ]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# El modelo: Convolutional neural network (CNN)\n",
                "\n",
                "Lo primero que hacemos dividir el conunto total de imágenes en dos conjuntos siguiendo la proporción (80%/20%). Es decir, vamos a entrenar el algoritmo con el 80% de las imágenes y validarlo con el 20% restante.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "set.seed(2022)\n",
                "split <- sample(2, nrow(df), replace = T, prob = c(0.8, 0.2))\n",
                "train <- df[split == 1,]\n",
                "test <- df[split == 2,]\n",
                "train_target <- df[split == 1, 10001] # label in training dataset\n",
                "test_target <- df[split == 2, 10001] # label in testing dataset\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Ahora construimos nuestro modelo. Utilizamos una red neuronal de tres capas (función `layer_dense()`).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model <- keras_model_sequential() %>%\n",
                "  layer_dense(units = 512, activation = \"relu\") %>% \n",
                "  layer_dropout(0.4) %>%\n",
                "  layer_dense(units = 256, activation = \"relu\") %>%\n",
                "  layer_dropout(0.3) %>%\n",
                "  layer_dense(units = 128, activation = \"relu\") %>%\n",
                "  layer_dropout(0.2) %>%\n",
                "  layer_dense(units = 2, activation = 'softmax')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compilamos el modelo con la optimización para una clasificación binaria. Es decir, aquí clasificamos si el paciente tiene enfermedad o no la tiene.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model %>%\n",
                "  compile(optimizer = 'adam',\n",
                "          loss = 'binary_crossentropy', \n",
                "          metrics = c('accuracy'))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Convertimos las etiquetas de enfermedad/no-enfermedad a un tipo de datos de tipo factor o categórico.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_label <- to_categorical(train_target)\n",
                "test_label <- to_categorical(test_target)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una vez entrenado el modelo, vamos a intentar hacer un ajuste sobre el 20% de los datos que dejamos para test.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fit_dissease <- model %>%\n",
                "  fit(x = train,\n",
                "      y = train_label, \n",
                "      epochs = 25,\n",
                "      batch_size = 512, # try also 256, 512\n",
                "      verbose = 2,\n",
                "      validation_split = 0.2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Una visualización rápida sobre como se comporta el algoritmo sobre las imágenes que hemos reservado para validar.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot(fit_dissease)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Calculamos las métricas de rendimiento del algoritmo.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model %>%\n",
                "  evaluate(test, test_label)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Hacemos ahora algunas predicciones sobre imágenes de pacientes. Es decir, una vez entrenado y validado el algoritmo, nos preguntamos como va a clasiificar las imágenes que le vamos a dar ahora. Como sabemos \"la verdad\" (lo que se denomina el ground truth) sobre las imágenes, comparamos el resultado de la predicción con la verdad.\n",
                "Para comprobar los resultados de la predicción (que variarán en función del número de imágenes que se usen en el entrenamiento) se utiliza lo que en ciencia de datos se denomina la matriz de confusión. La matriz de confusión:\n",
                "\n",
                "* coloca en la posición 1,1 los casos que SI tenían enfermedad y el modelo clasifica como \"con enfermedad\"\n",
                "* coloca en la posición 2,2, los casos que NO tenían enfermedad y el modelo clasifica como \"sin enfermedad\"\n",
                "\n",
                "Es decir, estas son las posiciones en las que el modelo \"acierta\" en su clasificación.\n",
                "\n",
                "En las posiciones contrarias, es decir, la 1,2 y la 2,1 son las posiciones en las que el modelo se \"equivoca\". Así, la 1,2 son los resultados que el modelo clasifica como CON enfermedad y la realidad es que eran pacientes sanos. La posición  2,1 justo lo contrario.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictedclasses <- model %>%\n",
                "  predict(test) %>% `>`(0.5) %>% k_cast(\"int32\")\n",
                "table(Prediction = as.numeric(predictedclasses[,2]), Truth = test_target)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Salvamos el modelo para más adelante.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#save_model_tf(model, \"model/disseasemodel\") # save the model\n",
                "save_model_hdf5(model, \"model/disseasemodel\") # save the model\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Conclusiones\n",
                "\n",
                "Hemos entrenado una algoritmo de tipo CNN Convolutional neural network-CNN para realizar clasificaciones binarias (enfermo vs no-enfermo) sobre un conjunto de imágenes de rayos-x de pecho tanto de pacientes sanos como de pacientes con varias patologías. Por sencillez, hemos escogido pacientes sanos y pacientes que presentan un Pneumothorax previamente identificado por un médico. El resultado del entrenamiento nos ofrece un algoritmo\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
