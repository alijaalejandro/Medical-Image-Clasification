{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8446ee",
   "metadata": {},
   "source": [
    "`{r setup, include=FALSE} knitr::opts_chunk$set(echo = TRUE,                        cache = TRUE,                        message = FALSE,                        warning = FALSE,                        dpi = 600)`\n",
    "\n",
    "# Introducción\n",
    "\n",
    "En este ejemplo, mostramos la capacidad de los algoritmos de Deep\n",
    "Learning para clasificar imágenes de radiodiagnóstico médico. El\n",
    "objetivo de este proyecto es entrenar a un algoritmo para que sea capaz\n",
    "de clasificar automáticamente una imágen de una radiografía de pecho en\n",
    "dos categorías (enferma vs no-enferma).\n",
    "\n",
    "# Proyectos previos\n",
    "\n",
    "Este proyecto es una adaptación del proyecto original de Michael Blum\n",
    "[tweeted](https://twitter.com/mblum_g/status/1475940763716444161?s=20)\n",
    "sobre el desafío [STOIC2021 - dissease-19 AI\n",
    "challenge](https://stoic2021.grand-challenge.org/stoic2021/). El\n",
    "proyecto roiginal de Michael partía de un conjunto de imágenes de\n",
    "pacientes con patología dissease-19 junto con otros pacientes sanos para\n",
    "hacer de contraste. Del proyecto original de Michael, [Olivier\n",
    "Gimenez](https://oliviergimenez.github.io/) utilizó un conjunto de datos\n",
    "similar al del proyetco original publicado en una competición de\n",
    "[Kaggle](https://en.wikipedia.org/wiki/Kaggle) repository\n",
    "<https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset>. La razón\n",
    "de utilizar este nuevo dataset es que era considerablemente más\n",
    "manejable que el original (280GB). El nuevo dataset pesaba alrededor de\n",
    "250MB y contenía algo más de 1000 imágenes de pacientes sanos y\n",
    "enfermos. El código del proyecto de Olivier puede encontrase en\n",
    "[Github](https://github.com/oliviergimenez/bin-image-classif).\n",
    "\n",
    "# Conjunto de Datos\n",
    "\n",
    "En nuestro caso, inspirándonos en estos dos fantásticos proyectos\n",
    "previos, damos un paso más. En este proyecto, partimos de un conjunto de\n",
    "datos (imágenes médicas) de radio-diagnóstico que están disponibles en\n",
    "el repositorio abierto del [NIH](https://clinicalcenter.nih.gov/). El\n",
    "Centro Clínico NIH es un hospital dedicado únicamente a la investigación\n",
    "clínica en el campus de los Institutos Nacionales de Salud en Bethesda,\n",
    "Maryland (EEUU). En el post [10 repositorios de datos públicos\n",
    "relacionados con la salud y el\n",
    "bienestar](https://datos.gob.es/es/noticia/10-repositorios-de-datos-publicos-relacionados-con-la-salud-y-el-bienestar)\n",
    "se cita al NIH como uno de los orígenes de datos sanitarios de calidad.\n",
    "\n",
    "En particular, nuestro conjunto de datos está disponible públicamente\n",
    "[aquí](https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/36938765345).\n",
    "El repositorio incluye toda la información necesario para usarlo y en la\n",
    "descripción los autores comentan:\n",
    "\n",
    "> El examen de rayos X de tórax es uno de los exámenes de imágenes\n",
    "> médicas más frecuentes y rentables. Sin embargo, el diagnóstico\n",
    "> clínico de la radiografía de tórax puede ser un desafío y, a veces, se\n",
    "> cree que es más difícil que el diagnóstico mediante imágenes de\n",
    "> [TC](https://es.wikipedia.org/wiki/Tomograf%C3%ADa_axial_computarizada)\n",
    "> (Tomografía Computerizada) de tórax\\_\n",
    "\n",
    "El conjunto de datos de rayos X de tórax comprende **112.120** imágenes\n",
    "de rayos X de vista frontal de **30.805** pacientes únicos con las\n",
    "**etiquetas de imágenes de catorce enfermedades** extraídas de texto\n",
    "(donde cada imagen puede tener múltiples etiquetas), extraídas de los\n",
    "informes radiológicos asociados utilizando procesamiento de lenguaje\n",
    "natural.\n",
    "\n",
    "Ejemplo de imágen del repositorio: <span class=\"image\">imagen de\n",
    "paciente sano</span>\n",
    "\n",
    "# El código paso a paso\n",
    "\n",
    "## Carga de dependencias\n",
    "\n",
    "Lo primero que debemos hacer es cargar las dependencias (librerías) que\n",
    "vamos a necesitar en nuestro análisis. El paquete de R más\n",
    "representativo de este conjunto de dependencias es\n",
    "[Keras](https://keras.io/). En este [post]() ya comentamos sobre el uso\n",
    "de Keras como framework de Deep Learning.\n",
    "\n",
    "``` {r}\n",
    "library(tidyverse)\n",
    "library(rmarkdown)\n",
    "theme_set(theme_light())\n",
    "library(keras)\n",
    "```\n",
    "\n",
    "# Lectura de datos\n",
    "\n",
    "Utilizando esta función leemos y preprocesamos todas las imágenes con\n",
    "las que vamos a querer trabajar. Esta función procede del [post\n",
    "original](https://rpubs.com/spalladino14/653239) escrita por [Spencer\n",
    "Palladino](https://www.linkedin.com/in/spencer-palladino/).\n",
    "\n",
    "``` {r}\n",
    "process_pix <- function(lsf) {\n",
    "  img <- lapply(lsf, image_load, color_mode = \"grayscale\") # grayscale the image\n",
    "  arr <- lapply(img, image_to_array) # turns it into an array\n",
    "  arr_resized <- lapply(arr, image_array_resize, \n",
    "                        height = 100, \n",
    "                        width = 100) # resize\n",
    "  arr_normalized <- normalize(arr_resized, axis = 1) #normalize to make small numbers \n",
    "  return(arr_normalized)\n",
    "}\n",
    "```\n",
    "\n",
    "En este fragmento de código cargamos las imágenes desde de los\n",
    "directorios donde las hemos dejado previamente.\n",
    "\n",
    "\\`\\`\\`{r eval = TRUE} \\# Imágenes de personas CON patologías\n",
    "\n",
    "lsf \\<- list.files(“../data/Pneumothorax/”, full.names = TRUE)\n",
    "\n",
    "# Restrinjo la lista a 1000 elementos.\n",
    "\n",
    "lsf2 \\<- lsf\\[1:100\\]\n",
    "\n",
    "dissease \\<- process_pix(lsf2)\n",
    "\n",
    "dissease \\<- dissease\\[,,,1\\] dissease_reshaped \\<-\n",
    "array_reshape(dissease, c(nrow(dissease), 100\\*100))\n",
    "\n",
    "# Imágenes de personas SIN patologías\n",
    "\n",
    "lsf \\<- list.files(“../data/No-Finding/”, full.names = TRUE)\n",
    "\n",
    "# Restrinjo la lista a 1000 elementos.\n",
    "\n",
    "lsf3 \\<- lsf\\[1:100\\]\n",
    "\n",
    "ndissease \\<- process_pix(lsf3) ndissease \\<- ndissease\\[,,,1\\]\n",
    "ndissease_reshaped \\<- array_reshape(ndissease, c(nrow(ndissease),\n",
    "100\\*100))\n",
    "\n",
    "\n",
    "    Tenemos `r nrow(dissease_reshaped)` imágenes de rayos-x de personas con enfermedad y `r nrow(dissease_reshaped)` imágenes de personas sin enfermedad.\n",
    "\n",
    "    # Visualización previa de los datos/imágenes\n",
    "\n",
    "    ```{r}\n",
    "    scandissease <- reshape2::melt(dissease[10,,])\n",
    "    plotdissease <- scandissease %>%\n",
    "      ggplot() +\n",
    "      aes(x = Var1, y = Var2, fill = value) + \n",
    "      geom_raster() +\n",
    "      labs(x = NULL, y = NULL, title = \"Raxos-x de personas con enfermedad\") + \n",
    "      scale_fill_viridis_c() + \n",
    "      theme(legend.position = \"none\")\n",
    "\n",
    "    scanndissease <- reshape2::melt(ndissease[10,,])\n",
    "    plotndissease <- scanndissease %>%\n",
    "      ggplot() +\n",
    "      aes(x = Var1, y = Var2, fill = value) + \n",
    "      geom_raster() +\n",
    "      labs(x = NULL, y = NULL, title = \"Raxos-x de personas sin enfermedad\") + \n",
    "      scale_fill_viridis_c() + \n",
    "      theme(legend.position = \"none\")\n",
    "\n",
    "    library(patchwork)\n",
    "    plotdissease + plotndissease\n",
    "\n",
    "# Comenzamos el análisis\n",
    "\n",
    "Lo primero que vamos a hacer es mezclar las imágenes de pacientes con\n",
    "enfermedad y sin ella.\n",
    "\n",
    "``` {r}\n",
    "df <- rbind(cbind(dissease_reshaped, 1), # 1 = dissease\n",
    "            cbind(ndissease_reshaped, 0)) # 0 = no dissease\n",
    "set.seed(1234)\n",
    "shuffle <- sample(nrow(df), replace = F)\n",
    "df <- df[shuffle, ]\n",
    "```\n",
    "\n",
    "# El modelo: Convolutional neural network (CNN)\n",
    "\n",
    "Lo primero que hacemos dividir el conunto total de imágenes en dos\n",
    "conjuntos siguiendo la proporción (80%/20%). Es decir, vamos a entrenar\n",
    "el algoritmo con el 80% de las imágenes y validarlo con el 20% restante.\n",
    "\n",
    "``` {r}\n",
    "set.seed(2022)\n",
    "split <- sample(2, nrow(df), replace = T, prob = c(0.8, 0.2))\n",
    "train <- df[split == 1,]\n",
    "test <- df[split == 2,]\n",
    "train_target <- df[split == 1, 10001] # label in training dataset\n",
    "test_target <- df[split == 2, 10001] # label in testing dataset\n",
    "```\n",
    "\n",
    "Ahora construimos nuestro modelo. Utilizamos una red neuronal de tres\n",
    "capas (función `layer_dense()`).\n",
    "\n",
    "``` {r}\n",
    "model <- keras_model_sequential() %>%\n",
    "  layer_dense(units = 512, activation = \"relu\") %>% \n",
    "  layer_dropout(0.4) %>%\n",
    "  layer_dense(units = 256, activation = \"relu\") %>%\n",
    "  layer_dropout(0.3) %>%\n",
    "  layer_dense(units = 128, activation = \"relu\") %>%\n",
    "  layer_dropout(0.2) %>%\n",
    "  layer_dense(units = 2, activation = 'softmax')\n",
    "```\n",
    "\n",
    "Compilamos el modelo con la optimizacion para una clasificación binaria.\n",
    "Es decir, aquí clasificamos si el paciente tiene enfermedad o no la\n",
    "tiene.\n",
    "\n",
    "``` {r}\n",
    "model %>%\n",
    "  compile(optimizer = 'adam',\n",
    "          loss = 'binary_crossentropy', \n",
    "          metrics = c('accuracy'))\n",
    "```\n",
    "\n",
    "Convertimos las etiquetas de enfermedad/no-enfermedad a un tipo de datos\n",
    "de tipo factor o categórico.\n",
    "\n",
    "``` {r}\n",
    "train_label <- to_categorical(train_target)\n",
    "test_label <- to_categorical(test_target)\n",
    "```\n",
    "\n",
    "Una vez entrenado el modelo, vamos a intentar hacer un ajuste sobre el\n",
    "20% de los datos que dejamos para test.\n",
    "\n",
    "``` {r}\n",
    "fit_dissease <- model %>%\n",
    "  fit(x = train,\n",
    "      y = train_label, \n",
    "      epochs = 25,\n",
    "      batch_size = 512, # try also 256, 512\n",
    "      verbose = 2,\n",
    "      validation_split = 0.2)\n",
    "```\n",
    "\n",
    "Una visualización rápida sobre como se comporta el algoritmo sobre las\n",
    "imágenes que hemos reservado para validar.\n",
    "\n",
    "``` {r}\n",
    "plot(fit_dissease)\n",
    "```\n",
    "\n",
    "Calculamos las métricas de rendimiento del algoritmo.\n",
    "\n",
    "``` {r}\n",
    "model %>%\n",
    "  evaluate(test, test_label)\n",
    "```\n",
    "\n",
    "Hacemos ahora algunas predicciones sobre imágenes de pacientes. Es\n",
    "decir, una vez entrenado y validado el algoritmo, nos preguntamos como\n",
    "va a clasiificar las imágenes que le vamos a dar ahora. Como sabemos “la\n",
    "verdad” (lo que se denomina el ground truth) sobre las imágenes,\n",
    "comparamos el resultado de la predicción con la verdad (lo que se\n",
    "denomina una tabla de confusión)\n",
    "\n",
    "``` {r}\n",
    "predictedclasses <- model %>%\n",
    "  predict(test) %>% `>`(0.5) %>% k_cast(\"int32\")\n",
    "table(Prediction = as.numeric(predictedclasses[,2]), Truth = test_target)\n",
    "```\n",
    "\n",
    "Muy genial. XXX se clasifica erróneamente como enfermo. Guardemos\n",
    "nuestro modelo para un uso posterior.\n",
    "\n",
    "`{r eval = FALSE} save_model_tf(model, \"model/disseasemodel\") # save the model`\n",
    "\n",
    "# Conclusiones\n",
    "\n",
    "Hemos entrenado una algoritmo de tipo CNN Convolutional neural\n",
    "network-CNN para realizar clasificaciones binarias (enfermo vs\n",
    "no-enfermo) sobre un conjunto de imágenes de rayos-x de pecho tanto de\n",
    "pacientes sanos como de pacientes con varias patologías. Por sencillez,\n",
    "hemos escogido pacientes sanos y pacientes que presentan un Pneumothorax\n",
    "previamente identificado por un médico. El resultado del entrenamiento\n",
    "nos ofrece un algoritmo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
